!!>

  parallel-3D-CA: Parallel 3-D Celluar Automaton
                                  Akira Kageyama
                          kage@port.kobe-u.ac.jp
                                 Kobe University

  Note:
   * Written in "E-language". Apply "efpp.sh" for Fortran 2003.
   * We take the ``Keep it simple'' approach:
       + The grid spacings in three (x,y, and z) directions
         are all the same, i.e., dx=dy=dz.
       + Each MPI process has exactly the same volume of space as
         well as the grid spans. Therefore, each process has the
         same size of arrays for variables.
       + We do not care about the memory size. We take the
         so-called "rich-man's approach".
       + We also disregard the interprocess communication
         redundancy. Simplicity surpasses communication stinginess.

  mpidd.e03
    * MPI-based Domain Decomposition Parallelization Utility

  History
    2022.07.18: Separate from mpiut.ef.

!!<

module mpidd_m
  use mpi
  use mpiut_m
  use constants_m, only : SI, DI, SR, DR, NXPP, NYPP, NZPP, NXPP1, NYPP1, NZPP1
  use constants_m, only : NPROC_X, NPROC_Y, NPROC_Z
  use ut_m
  implicit none
  private
  public :: & !< routines >!
            mpidd__exchange,                 &
            mpidd__proc_pos_ijk_to_rank,     &
            mpidd__proc_pos_ijk_to_str,      &
            mpidd__rank_to_proc_pos_ijk

  type, public :: mpidd__proc_pos_ijk_t
    integer(SI) :: i, j, k
  end type mpidd__proc_pos_ijk_t

  type, public :: mpidd__rank_of_neighbor_t
    integer(SI) :: ip1, im1  ! The two neighbors in x-direction.
    integer(SI) :: jp1, jm1  !               ... in y-direction.
    integer(SI) :: kp1, km1  !               ... in z-direction.
  end type mpidd__rank_of_neighbor_t

  interface mpidd__exchange
     module procedure exchange3d_dr_1,     &
                      exchange3d_dr_2,     &
                      exchange3d_dr_3,     &
                      exchange3d_dr_4,     &
                      exchange3d_dr_5,     &
                      exchange3d_dr_8,     &
                      exchange3d_si_1
  end interface

  interface mpidd__proc_pos_ijk_to_rank
    module procedure proc_pos_ijk_int_to_rank,     &
                     proc_pos_ijk_type_to_rank
  end interface


contains


!!!>
!    Private
!!!<


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_si_1( comm, rank_of_neighbor,   &
                              f01 )
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_si_t) <io> :: f01
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    integer(SI), dimension(0:NYPP1,0:NZPP1,1) :: send_buff_ip1, send_buff_im1, &
                                                 recv_buff_ip1, recv_buff_im1
    integer(SI), dimension(0:NXPP1,0:NZPP1,1) :: send_buff_jp1, send_buff_jm1, &
                                                 recv_buff_jp1, recv_buff_jm1
    integer(SI), dimension(0:NXPP1,0:NYPP1,1) :: send_buff_kp1, send_buff_km1, &
                                                 recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI) :: ncount, ierr, j, k
      integer(SI), dimension(2) :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*1

      call MPI_IRECV( recv_buff_ip1, ncount,        &
                      MPI_INTEGER,                  &
                      rank_of_neighbor.ip1,         &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,        &
                      MPI_INTEGER,                  &
                      rank_of_neighbor.im1,         &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,         &
                     MPI_INTEGER,                   &
                     rank_of_neighbor.ip1,          &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,         &
                     MPI_INTEGER,                   &
                     rank_of_neighbor.im1,          &
                     0, comm, ierr )
      call MPI_WAITALL( 2, requests, status, ierr )

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI) :: ncount, ierr, i, k
      integer(SI), dimension(2) :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*1

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_INTEGER,                    &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_INTEGER,                    &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_INTEGER,                     &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_INTEGER,                     &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI) :: ncount, ierr, i, j
      integer(SI), dimension(2) :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*1

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_INTEGER,                    &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_INTEGER,                    &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_INTEGER,                     &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_INTEGER,                     &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_si_1


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_1( comm, rank_of_neighbor,   &
                              f01 )
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,1) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,1) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,1) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI) :: ncount, ierr, j, k
      integer(SI), dimension(2) :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*1

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*1

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*1

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_1


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_2( comm, rank_of_neighbor,                       &
                              f01, f02 )
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01,f02
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,2) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,2) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,2) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, j, k

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)
          send_buff_ip1(j,k,2) = f02(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
          send_buff_im1(j,k,2) = f02(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*2

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
            f02(NXPP1,j,k) = recv_buff_ip1(j,k,2)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
            f02(0,j,k) = recv_buff_im1(j,k,2)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)
          send_buff_jp1(i,k,2) = f02(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
          send_buff_jm1(i,k,2) = f02(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*2

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
            f02(i,NYPP1,k) = recv_buff_jp1(i,k,2)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
            f02(i,0,k) = recv_buff_jm1(i,k,2)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)
          send_buff_kp1(i,j,2) = f02(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
          send_buff_km1(i,j,2) = f02(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*2

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
            f02(i,j,NZPP1) = recv_buff_kp1(i,j,2)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
            f02(i,j,0) = recv_buff_km1(i,j,2)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_2


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_3( comm, rank_of_neighbor,    &
                              f01, f02, f03)
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01,f02,f03
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,3) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,3) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,3) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, j, k

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)
          send_buff_ip1(j,k,2) = f02(NXPP,j,k)
          send_buff_ip1(j,k,3) = f03(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
          send_buff_im1(j,k,2) = f02(   1,j,k)
          send_buff_im1(j,k,3) = f03(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*3

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
            f02(NXPP1,j,k) = recv_buff_ip1(j,k,2)
            f03(NXPP1,j,k) = recv_buff_ip1(j,k,3)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
            f02(0,j,k) = recv_buff_im1(j,k,2)
            f03(0,j,k) = recv_buff_im1(j,k,3)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)
          send_buff_jp1(i,k,2) = f02(i,NYPP,k)
          send_buff_jp1(i,k,3) = f03(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
          send_buff_jm1(i,k,2) = f02(i,   1,k)
          send_buff_jm1(i,k,3) = f03(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*3

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
            f02(i,NYPP1,k) = recv_buff_jp1(i,k,2)
            f03(i,NYPP1,k) = recv_buff_jp1(i,k,3)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
            f02(i,0,k) = recv_buff_jm1(i,k,2)
            f03(i,0,k) = recv_buff_jm1(i,k,3)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)
          send_buff_kp1(i,j,2) = f02(i,j,NZPP)
          send_buff_kp1(i,j,3) = f03(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
          send_buff_km1(i,j,2) = f02(i,j,   1)
          send_buff_km1(i,j,3) = f03(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*3

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
            f02(i,j,NZPP1) = recv_buff_kp1(i,j,2)
            f03(i,j,NZPP1) = recv_buff_kp1(i,j,3)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
            f02(i,j,0) = recv_buff_km1(i,j,2)
            f03(i,j,0) = recv_buff_km1(i,j,3)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_3


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_4( comm, rank_of_neighbor,                       &
                              f01, f02, f03, f04 )
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01,f02,f03,f04
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,4) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,4) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,4) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, j, k

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)
          send_buff_ip1(j,k,2) = f02(NXPP,j,k)
          send_buff_ip1(j,k,3) = f03(NXPP,j,k)
          send_buff_ip1(j,k,4) = f04(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
          send_buff_im1(j,k,2) = f02(   1,j,k)
          send_buff_im1(j,k,3) = f03(   1,j,k)
          send_buff_im1(j,k,4) = f04(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*4

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
            f02(NXPP1,j,k) = recv_buff_ip1(j,k,2)
            f03(NXPP1,j,k) = recv_buff_ip1(j,k,3)
            f04(NXPP1,j,k) = recv_buff_ip1(j,k,4)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
            f02(0,j,k) = recv_buff_im1(j,k,2)
            f03(0,j,k) = recv_buff_im1(j,k,3)
            f04(0,j,k) = recv_buff_im1(j,k,4)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)
          send_buff_jp1(i,k,2) = f02(i,NYPP,k)
          send_buff_jp1(i,k,3) = f03(i,NYPP,k)
          send_buff_jp1(i,k,4) = f04(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
          send_buff_jm1(i,k,2) = f02(i,   1,k)
          send_buff_jm1(i,k,3) = f03(i,   1,k)
          send_buff_jm1(i,k,4) = f04(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*4

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
            f02(i,NYPP1,k) = recv_buff_jp1(i,k,2)
            f03(i,NYPP1,k) = recv_buff_jp1(i,k,3)
            f04(i,NYPP1,k) = recv_buff_jp1(i,k,4)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
            f02(i,0,k) = recv_buff_jm1(i,k,2)
            f03(i,0,k) = recv_buff_jm1(i,k,3)
            f04(i,0,k) = recv_buff_jm1(i,k,4)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)
          send_buff_kp1(i,j,2) = f02(i,j,NZPP)
          send_buff_kp1(i,j,3) = f03(i,j,NZPP)
          send_buff_kp1(i,j,4) = f04(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
          send_buff_km1(i,j,2) = f02(i,j,   1)
          send_buff_km1(i,j,3) = f03(i,j,   1)
          send_buff_km1(i,j,4) = f04(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*4

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
            f02(i,j,NZPP1) = recv_buff_kp1(i,j,2)
            f03(i,j,NZPP1) = recv_buff_kp1(i,j,3)
            f04(i,j,NZPP1) = recv_buff_kp1(i,j,4)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
            f02(i,j,0) = recv_buff_km1(i,j,2)
            f03(i,j,0) = recv_buff_km1(i,j,3)
            f04(i,j,0) = recv_buff_km1(i,j,4)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_4


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_5( comm, rank_of_neighbor,            &
                              f01, f02, f03, f04, f05)
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01,f02,f03,f04,f05
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,5) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,5) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,5) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, j, k

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)
          send_buff_ip1(j,k,2) = f02(NXPP,j,k)
          send_buff_ip1(j,k,3) = f03(NXPP,j,k)
          send_buff_ip1(j,k,4) = f04(NXPP,j,k)
          send_buff_ip1(j,k,5) = f05(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
          send_buff_im1(j,k,2) = f02(   1,j,k)
          send_buff_im1(j,k,3) = f03(   1,j,k)
          send_buff_im1(j,k,4) = f04(   1,j,k)
          send_buff_im1(j,k,5) = f05(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*5

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
            f02(NXPP1,j,k) = recv_buff_ip1(j,k,2)
            f03(NXPP1,j,k) = recv_buff_ip1(j,k,3)
            f04(NXPP1,j,k) = recv_buff_ip1(j,k,4)
            f05(NXPP1,j,k) = recv_buff_ip1(j,k,5)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
            f02(0,j,k) = recv_buff_im1(j,k,2)
            f03(0,j,k) = recv_buff_im1(j,k,3)
            f04(0,j,k) = recv_buff_im1(j,k,4)
            f05(0,j,k) = recv_buff_im1(j,k,5)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)
          send_buff_jp1(i,k,2) = f02(i,NYPP,k)
          send_buff_jp1(i,k,3) = f03(i,NYPP,k)
          send_buff_jp1(i,k,4) = f04(i,NYPP,k)
          send_buff_jp1(i,k,5) = f05(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
          send_buff_jm1(i,k,2) = f02(i,   1,k)
          send_buff_jm1(i,k,3) = f03(i,   1,k)
          send_buff_jm1(i,k,4) = f04(i,   1,k)
          send_buff_jm1(i,k,5) = f05(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*5

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
            f02(i,NYPP1,k) = recv_buff_jp1(i,k,2)
            f03(i,NYPP1,k) = recv_buff_jp1(i,k,3)
            f04(i,NYPP1,k) = recv_buff_jp1(i,k,4)
            f05(i,NYPP1,k) = recv_buff_jp1(i,k,5)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
            f02(i,0,k) = recv_buff_jm1(i,k,2)
            f03(i,0,k) = recv_buff_jm1(i,k,3)
            f04(i,0,k) = recv_buff_jm1(i,k,4)
            f05(i,0,k) = recv_buff_jm1(i,k,5)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)
          send_buff_kp1(i,j,2) = f02(i,j,NZPP)
          send_buff_kp1(i,j,3) = f03(i,j,NZPP)
          send_buff_kp1(i,j,4) = f04(i,j,NZPP)
          send_buff_kp1(i,j,5) = f05(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
          send_buff_km1(i,j,2) = f02(i,j,   1)
          send_buff_km1(i,j,3) = f03(i,j,   1)
          send_buff_km1(i,j,4) = f04(i,j,   1)
          send_buff_km1(i,j,5) = f05(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*5

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
            f02(i,j,NZPP1) = recv_buff_kp1(i,j,2)
            f03(i,j,NZPP1) = recv_buff_kp1(i,j,3)
            f04(i,j,NZPP1) = recv_buff_kp1(i,j,4)
            f05(i,j,NZPP1) = recv_buff_kp1(i,j,5)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
            f02(i,j,0) = recv_buff_km1(i,j,2)
            f03(i,j,0) = recv_buff_km1(i,j,3)
            f04(i,j,0) = recv_buff_km1(i,j,4)
            f05(i,j,0) = recv_buff_km1(i,j,5)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_5


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  subroutine exchange3d_dr_8( comm, rank_of_neighbor,                       &
                              f01, f02, f03, f04, f05, f06, f07, f08)
    integer(SI) <in> :: comm
    type(mpidd__rank_of_neighbor_t) <in> :: rank_of_neighbor
    type(array3d_dr_t) <io> :: f01,f02,f03,f04,f05,f06,f07,f08
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    real(DR), dimension(0:NYPP1,0:NZPP1,8) :: send_buff_ip1, send_buff_im1, &
                                              recv_buff_ip1, recv_buff_im1
    real(DR), dimension(0:NXPP1,0:NZPP1,8) :: send_buff_jp1, send_buff_jm1, &
                                              recv_buff_jp1, recv_buff_jm1
    real(DR), dimension(0:NXPP1,0:NYPP1,8) :: send_buff_kp1, send_buff_km1, &
                                              recv_buff_kp1, recv_buff_km1
    call iN_i_direction
    call iN_j_direction
    call iN_k_direction

  contains

    subroutine iN_i_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, j, k

      do k full
        do j full
          send_buff_ip1(j,k,1) = f01(NXPP,j,k)
          send_buff_ip1(j,k,2) = f02(NXPP,j,k)
          send_buff_ip1(j,k,3) = f03(NXPP,j,k)
          send_buff_ip1(j,k,4) = f04(NXPP,j,k)
          send_buff_ip1(j,k,5) = f05(NXPP,j,k)
          send_buff_ip1(j,k,6) = f06(NXPP,j,k)
          send_buff_ip1(j,k,7) = f07(NXPP,j,k)
          send_buff_ip1(j,k,8) = f08(NXPP,j,k)

          send_buff_im1(j,k,1) = f01(   1,j,k)
          send_buff_im1(j,k,2) = f02(   1,j,k)
          send_buff_im1(j,k,3) = f03(   1,j,k)
          send_buff_im1(j,k,4) = f04(   1,j,k)
          send_buff_im1(j,k,5) = f05(   1,j,k)
          send_buff_im1(j,k,6) = f06(   1,j,k)
          send_buff_im1(j,k,7) = f07(   1,j,k)
          send_buff_im1(j,k,8) = f08(   1,j,k)
        end do
      end do

      ncount = (NYPP1+1)*(NZPP1+1)*8

      call MPI_IRECV( recv_buff_ip1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.ip1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_im1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.im1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_ip1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.ip1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_im1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.im1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.ip1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(NXPP1,j,k) = recv_buff_ip1(j,k,1)
            f02(NXPP1,j,k) = recv_buff_ip1(j,k,2)
            f03(NXPP1,j,k) = recv_buff_ip1(j,k,3)
            f04(NXPP1,j,k) = recv_buff_ip1(j,k,4)
            f05(NXPP1,j,k) = recv_buff_ip1(j,k,5)
            f06(NXPP1,j,k) = recv_buff_ip1(j,k,6)
            f07(NXPP1,j,k) = recv_buff_ip1(j,k,7)
            f08(NXPP1,j,k) = recv_buff_ip1(j,k,8)
          end do
        end do
      end if
      if ( rank_of_neighbor.im1 /= MPI_PROC_NULL ) then
        do k full
          do j full
            f01(0,j,k) = recv_buff_im1(j,k,1)
            f02(0,j,k) = recv_buff_im1(j,k,2)
            f03(0,j,k) = recv_buff_im1(j,k,3)
            f04(0,j,k) = recv_buff_im1(j,k,4)
            f05(0,j,k) = recv_buff_im1(j,k,5)
            f06(0,j,k) = recv_buff_im1(j,k,6)
            f07(0,j,k) = recv_buff_im1(j,k,7)
            f08(0,j,k) = recv_buff_im1(j,k,8)
          end do
        end do
      end if
    end subroutine iN_i_direction

    subroutine iN_j_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, k

      do k full
        do i full
          send_buff_jp1(i,k,1) = f01(i,NYPP,k)
          send_buff_jp1(i,k,2) = f02(i,NYPP,k)
          send_buff_jp1(i,k,3) = f03(i,NYPP,k)
          send_buff_jp1(i,k,4) = f04(i,NYPP,k)
          send_buff_jp1(i,k,5) = f05(i,NYPP,k)
          send_buff_jp1(i,k,6) = f06(i,NYPP,k)
          send_buff_jp1(i,k,7) = f07(i,NYPP,k)
          send_buff_jp1(i,k,8) = f08(i,NYPP,k)

          send_buff_jm1(i,k,1) = f01(i,   1,k)
          send_buff_jm1(i,k,2) = f02(i,   1,k)
          send_buff_jm1(i,k,3) = f03(i,   1,k)
          send_buff_jm1(i,k,4) = f04(i,   1,k)
          send_buff_jm1(i,k,5) = f05(i,   1,k)
          send_buff_jm1(i,k,6) = f06(i,   1,k)
          send_buff_jm1(i,k,7) = f07(i,   1,k)
          send_buff_jm1(i,k,8) = f08(i,   1,k)
        end do
      end do

      ncount = (NXPP1+1)*(NZPP1+1)*8

      call MPI_IRECV( recv_buff_jp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_jm1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.jm1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_jp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_jm1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.jm1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.jp1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,NYPP1,k) = recv_buff_jp1(i,k,1)
            f02(i,NYPP1,k) = recv_buff_jp1(i,k,2)
            f03(i,NYPP1,k) = recv_buff_jp1(i,k,3)
            f04(i,NYPP1,k) = recv_buff_jp1(i,k,4)
            f05(i,NYPP1,k) = recv_buff_jp1(i,k,5)
            f06(i,NYPP1,k) = recv_buff_jp1(i,k,6)
            f07(i,NYPP1,k) = recv_buff_jp1(i,k,7)
            f08(i,NYPP1,k) = recv_buff_jp1(i,k,8)
          end do
        end do
      end if
      if ( rank_of_neighbor.jm1 /= MPI_PROC_NULL ) then
        do k full
          do i full
            f01(i,0,k) = recv_buff_jm1(i,k,1)
            f02(i,0,k) = recv_buff_jm1(i,k,2)
            f03(i,0,k) = recv_buff_jm1(i,k,3)
            f04(i,0,k) = recv_buff_jm1(i,k,4)
            f05(i,0,k) = recv_buff_jm1(i,k,5)
            f06(i,0,k) = recv_buff_jm1(i,k,6)
            f07(i,0,k) = recv_buff_jm1(i,k,7)
            f08(i,0,k) = recv_buff_jm1(i,k,8)
          end do
        end do
      end if
    end subroutine iN_j_direction

    subroutine iN_k_direction
      integer(SI), dimension(2)                 :: requests
      integer(SI), dimension(MPI_STATUS_SIZE,2) :: status
      integer(SI)                               :: ncount, ierr, i, j

      do j full
        do i full
          send_buff_kp1(i,j,1) = f01(i,j,NZPP)
          send_buff_kp1(i,j,2) = f02(i,j,NZPP)
          send_buff_kp1(i,j,3) = f03(i,j,NZPP)
          send_buff_kp1(i,j,4) = f04(i,j,NZPP)
          send_buff_kp1(i,j,5) = f05(i,j,NZPP)
          send_buff_kp1(i,j,6) = f06(i,j,NZPP)
          send_buff_kp1(i,j,7) = f07(i,j,NZPP)
          send_buff_kp1(i,j,8) = f08(i,j,NZPP)

          send_buff_km1(i,j,1) = f01(i,j,   1)
          send_buff_km1(i,j,2) = f02(i,j,   1)
          send_buff_km1(i,j,3) = f03(i,j,   1)
          send_buff_km1(i,j,4) = f04(i,j,   1)
          send_buff_km1(i,j,5) = f05(i,j,   1)
          send_buff_km1(i,j,6) = f06(i,j,   1)
          send_buff_km1(i,j,7) = f07(i,j,   1)
          send_buff_km1(i,j,8) = f08(i,j,   1)
        end do
      end do

      ncount = (NXPP1+1)*(NYPP1+1)*8

      call MPI_IRECV( recv_buff_kp1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.kp1,           &
                      0, comm, requests(1), ierr )
      call MPI_IRECV( recv_buff_km1, ncount,          &
                      MPI_DOUBLE_PRECISION,           &
                      rank_of_neighbor.km1,           &
                      1, comm, requests(2), ierr )
      call MPI_BARRIER( comm, ierr )

      call MPI_SEND( send_buff_kp1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.kp1,            &
                     1, comm, ierr )
      call MPI_SEND( send_buff_km1, ncount,           &
                     MPI_DOUBLE_PRECISION,            &
                     rank_of_neighbor.km1,            &
                     0, comm, ierr )
      call MPI_WAITALL(2, requests, status, ierr)

      if ( rank_of_neighbor.kp1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,NZPP1) = recv_buff_kp1(i,j,1)
            f02(i,j,NZPP1) = recv_buff_kp1(i,j,2)
            f03(i,j,NZPP1) = recv_buff_kp1(i,j,3)
            f04(i,j,NZPP1) = recv_buff_kp1(i,j,4)
            f05(i,j,NZPP1) = recv_buff_kp1(i,j,5)
            f06(i,j,NZPP1) = recv_buff_kp1(i,j,6)
            f07(i,j,NZPP1) = recv_buff_kp1(i,j,7)
            f08(i,j,NZPP1) = recv_buff_kp1(i,j,8)
          end do
        end do
      end if
      if ( rank_of_neighbor.km1 /= MPI_PROC_NULL ) then
        do j full
          do i full
            f01(i,j,0) = recv_buff_km1(i,j,1)
            f02(i,j,0) = recv_buff_km1(i,j,2)
            f03(i,j,0) = recv_buff_km1(i,j,3)
            f04(i,j,0) = recv_buff_km1(i,j,4)
            f05(i,j,0) = recv_buff_km1(i,j,5)
            f06(i,j,0) = recv_buff_km1(i,j,6)
            f07(i,j,0) = recv_buff_km1(i,j,7)
            f08(i,j,0) = recv_buff_km1(i,j,8)
          end do
        end do
      end if
    end subroutine iN_k_direction

  end subroutine exchange3d_dr_8


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  function proc_pos_ijk_int_to_rank( i, j, k ) result(rank)
    integer(SI) <in> :: i, j, k
    integer(SI) :: rank
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    !!>
      Purpose: Returns rank number for the subdomain at i,j,k.
       Author: Akira Kageyama
         Date: 2013.06.13 (revised)
    !!<

    if ( i < 0 .or. i >= NPROC_X  &
               .or.               &
         j < 0 .or. j >= NPROC_Y  &
               .or.               &
         k < 0 .or. k >= NPROC_Z ) then
      rank = MPI_PROC_NULL
    else
      rank = i + j*NPROC_X + k*NPROC_X*NPROC_Y
    end if
                        
  end function proc_pos_ijk_int_to_rank


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  function proc_pos_ijk_type_to_rank( ppijk ) result(rank)
    type(mpidd__proc_pos_ijk_t) <in> :: ppijk
    integer(SI) :: rank
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    rank = proc_pos_ijk_int_to_rank( ppijk.i, ppijk.j, ppijk.k )
                        
  end function proc_pos_ijk_type_to_rank  
  

!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  function mpidd__rank_to_proc_pos_ijk( rank ) result(ppijk)
    integer(SI) <in> :: rank
    type(mpidd__proc_pos_ijk_t) :: ppijk
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    !!>
      Purpose: Returns the process position (i,j,k) for the rank.
       Author: Akira Kageyama
         Date: 2022.07.18 (Revised)
    !!<

    call mpiut__assert( rank >= 0,  &
                        '<__FUNC__> negative rank!?' )
    call mpiut__assert( rank < NPROC_X*NPROC_Y*NPROC_Z,  &
                        '<__FUNC__> rank out of range.' )

    ppijk.k = rank / (NPROC_X*NPROC_Y)
    ppijk.j = mod( rank, NPROC_X*NPROC_Y ) / NPROC_X
    ppijk.i = mod( rank, NPROC_X )

  end function mpidd__rank_to_proc_pos_ijk


!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
  function mpidd__proc_pos_ijk_to_str( ppijk ) result(str)
    type(mpidd__proc_pos_ijk_t) <in> :: ppijk
    char(len=12) :: str ! e.g., "p012_035_064"
!__________  _________  ________ _______ ______ _____ ____ ___ __ _
!
    str = "p"                  & ! 1 letter
        // ut__i2c3( ppijk.i ) & ! 3 letters
        // '_'                 & ! 1 letter
        // ut__i2c3( ppijk.j ) & ! 3
        // '_'                 & ! 1
        // ut__i2c3( ppijk.k )   ! 3

  end function mpidd__proc_pos_ijk_to_str

end module mpidd_m
